<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="balisage-1-3.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-stylesheet type="text/xsl" href="balisage-proceedings-html.xsl"?>
<article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink">
  <title>The creature lives</title>
  <info>
    <abstract>
      <para>Abstract text will go here</para>
    </abstract>
    <author>
      <personname>
        <firstname>David</firstname>
        <othername>J.</othername>
        <surname>Birnbaum</surname>
      </personname>
      <personblurb>
        <para>David J. Birnbaum is Professor and Chair of the Department of Slavic Languages and
          Literatures at the University of Pittsburgh. He has been involved in the study of
          electronic text technology since the mid-1980s, has delivered presentations at a variety
          of electronic text technology conferences, and has served on the board of the Association
          for Computers and the Humanities, the editorial board of <emphasis role="ital">Markup
            languages: Theory and practice</emphasis>, and the Text Encoding Initiative Council.
          Much of his electronic text work intersects with his research in medieval Slavic
          manuscript studies, but he also often writes about issues in the philosophy of
          markup.</para>
      </personblurb>
      <affiliation>
        <jobtitle>Professor and Chair</jobtitle>
        <orgname>Department of Slavic Languages and Literatures, University of Pittsburgh</orgname>
      </affiliation>
      <email>djbpitt@gmail.com</email>
      <link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest"
        >http://www.obdurodon.org</link>
    </author>
    <author>
      <personname>
        <firstname>Ronald</firstname>
        <othername>Haentjens</othername>
        <surname>Dekker</surname>
      </personname>
      <personblurb>
        <para>Add blurb about Ronald</para>
      </personblurb>
      <affiliation>
        <jobtitle><!-- job title goes here--></jobtitle>
        <orgname><!-- organization name goes here--></orgname>
      </affiliation>
      <email><!-- email goes here --></email>
      <link xlink:type="simple" xlink:show="new" xlink:actuate="onRequest"
        ><!-- url to Ronalds main web presence goes here--></link>
    </author>
    <keywordset role="author">
      <keyword>graph database</keyword>
      <keyword>LMNL</keyword>
      <keyword>overlap</keyword>
      <keyword>discontinuity</keyword>
      <keyword>mixed content</keyword>
    </keywordset>
  </info>
  <section>
    <title>Introduction</title>
    <para><!--Add introductory paragraph here--></para>
  </section>
  <section>
    <title>Rationale for moving beyond XML</title>
    <note>Wendell himself discussed the relation between LMNL and OHCO in his 2014 Balisage paper here: <a ref="http://www.balisage.net/Proceedings/vol13/print/Piez01/BalisageVol13-Piez01.html">link to paper</a></note>
    <para>Textual data is unstructured. Markups needs to be added to extract information from it.
      The most popular markup format to store textual data and markup is XML. XML follows a
      hierarchial model that allows one to add structure to a file. This works well for dividing
      text into chapters and paragraphs. However there are limitations.</para>
    <para>Adding a second hierarcy is difficult, since XML markup syntax requires that the last
      opened tag is closed first. Adding the structure of the pages for example overlaps with the
      stucture of the chapters and paragraphs. This can be worked around by adding a second
      hierarchy as milestones instead of start and end elements.</para>
    <para>The problem here is that one hierarchiy is handled differently from the second hierarchy.
      The leading hierarchy is modeled using full start and elements.</para>
    <para>Modeling multiple hierarchies is possible in XML, but difficult because the second or
      third etc hierarchy needs to be modelled differently from the first hierarchy. This also leads
      to challenges when querying or transforming the data contained in the file.</para>
    <para>There are many real use cases where there are multiple hierarchies present in the data:
      poetry, stage plays.</para>
  </section>
  <section>
    <title>LMNL markup file format</title>
    <para>The LMNL markup file format removes the constraint that the last opened has to be closed
      first. That means that it is possible to model overlapping hierarchies in LMNL. To be more
      precise, it is possible to model annotations with one hierarchy, multiple hierarchies or no
      hierarchy at all. This allows for a great freedom to model all kinds of information on textual
      content. This is great from a content perspective. However LMNL is more expensive from a
      computational perspective.</para>
  </section>
  <section>
    <title>Conceptual model</title>
    <para>The conceptual datamodel behind is XML is the Document Object Model (DOM). The DOM
      represents a tree based data structure. The data model behind LMNL is different, in that it is
      based on ranges, based on offsets on textual content.</para>
  </section>
  <section>
    <title>Text as a graph</title>
    <para>This paper proposes to use a different data model than trees or ranges. It proposes to use
      a graph based model, we call text as graph (TAG). Graph models for text have been proposed
      before (GODDAG), but the model proposed in this paper differs in the fact that not just a
      directed graph is used, but a directed graph is used in combination with a hypergraph.</para>
  </section>
  <section>
    <title>Requirements for a text model</title>
    <para>
      Features: Support textual content and annotations. Overlapping annotations should be possible. Should allow annotations on annotations.
      Hierarchical content should be possible but not required.
      Read: queries for text or annotations.
      Write: added or modifying textual content, adding or modifying annotations.
      Scalability: The model should allow for large (needs to be defined better) documents.
      With the range conceptual model it is inexpensive to add extra annotation layers, however modifying the textual content is very expensive, since all the ranges of annotations that come after the point of insertion have to be recalculated.
      With the directed acyclic graph model it is inexpensive to add or change textual content, however since all the annotation nodes have to be connected to all the textual nodes involves this model scales badly with the number of textual nodes and the number of annotations.
      In the traditional tree model it is cheap to add or modify textual content and to add annotations, however there is only a single hierarchy. On top of that having a hierarchy is required.
      In the hypergraph approach it is inexpensive (we really should use O notations here) to add or modify textual content, adding annotations is not as cheap as it is with ranges, (a new set needs to be created and a bit needs to be set for every text node involved), but it cheaper than the DAG model, since hypergraphs can be stored as sets rather than having to model individual edges.
    </para>
  </section>
  <section>
    <title>Example use case: tokenization with markup</title>
    <para>
      In natural language processing tokenization is the process of breaking a string of characters up into individual words. Tokenization is done using regular expressions. Regular expressions however only work on textual data and not on markup. (See the famous stackoverflow post for reference). On top of that the tokens themselves add another layer of information to file/model/data/document (not sure what the right word to use is here), which can overlap with the already existing hierarchy in the document.
      A data model for text that can handle multiple overlapping hierarchies or layers of annotations and that allows read as well as write operations can help out here.
      During tokenization all of the markup can be put 'aside' if it were and the tokenizer only pays attention to the textual content. The individual token are markup in a separate annotation layer. The existing markup layer are only ignored during tokenization, and still exist in the data.
    </para>
  </section>
</article>
